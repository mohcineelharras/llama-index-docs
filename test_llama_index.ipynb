{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"NOOPE\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:1500/v1\"\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.embeddings import InstructorEmbedding\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "embed_model_inst = InstructorEmbedding(model_name=\"hkunlp/instructor-large\")\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model_inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "text_embeddings = embed_model_inst.get_text_embedding(\"AI is awesome!\")\n",
    "print(len(text_embeddings))\n",
    "#print(text_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "print(f\"Number of documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b587ba07b45a4fee811c4175251e4811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e7aaa9cf6a460db0d047bfb0960be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=service_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x00000139FFDAE0E0>\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "HTTP code 502 from API (<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html>\n<!-- FileName: index.html\n     Language: [en]\n-->\n<!--Head-->\n<head>\n  <meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\">\n  <title>Notification proxy</title>\n  <link rel=\"icon\" type=\"image/png\" href=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABmJLR0QA/wD/AP+gvaeTAAAA CXBIWXMAAC4jAAAuIwF4pT92AAAAB3RJTUUH4QscCiY57Z81SwAAAdhJREFUOMtt0ztsjXEY BvDfOU6Ixi2lEREVihAhymao6R8Jickl8i1iMRhZDIiFjYGFheW/NRHXhC9YtLFJ2qQlbk2k LnWpBi2ijqFvm6PxJf/le97nvT3PW1GUVdTlVDf9K8oOLMYNOf2YhlWh8h/SfCzFduzFbNzE VTyX00hjeEVRLsQWLMNctGIjqkF6i31Yjh704zM+oqeGnTiK7wG+x2V0y+lVdPUQm7EB67EE K9FZw4LIdhLdmCmnsX/GyukdbivKXnxFC46jpRYtjqJPTuMYi6oVzJDTb0U5B4cxLKdL+KIo X+NnFYNoxtppVeuYVGZH7OFTJG+LMd7UYuYPaEOXohTgiJxGFWUrDuJBLBVWhLzPqhjCC7Qr yoqc4ACOKMp52B9SnpfTn0iwGrPQX5XTVzzGJqyKgD5sxS3sDvJAtL8A7eiV01A1CF0Yx66Y /xouYCF65NTZsJ0OrMMNYRZyeonr2KMot8S/yeonGlzaHOM9ldP9iQRFWQv4CgZwWlGuiSR9 choMchPOYBHONVq5MiVbUa4OcDYu4h5+hdUPhc1PyenupFcqU5c1ueEJ2Y7FUp/gW3hkGGfl 9Cji/HuNExLWG1y4LV5TWPzO1ElPkCtyqv8FroChr3qq9H8AAAAASUVORK5CYII=\">\n  <script src=\"/mwg-internal/de5fs23hu73ds/files/javascript/sw.js\" type=\"text/javascript\" ></script>\n  <link rel=\"stylesheet\" href=\"/mwg-internal/de5fs23hu73ds/files/EDF-Template/stylesheet.css\" />\n</head>\n<!--/Head-->\n<!--Body-->\n<body onload=\"swOnLoad();\">\n<div id=\"warp\">\n    <a target=\"_blank\" href=\"http://localhost:1500/v1/chat/completions\" title=\"Page d'erreur complète\"><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAWCAYAAADTlvzyAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3wIZDyouwIzJ9QAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAB20lEQVRIx+2WPW/TYBCAn3PSgN2oKMZOascoQW0TiS0KAgmoZCYGBFtGEFOZGGBipH+AEdGJ3WslxEY3GCq2TEj8gFZsSBlAOYY2Td46Tp0qqhg46WTptc/PfduiqlykWFyw/FvA5zfF2QjEXxYJRCQUkfrRtVaTxmZFtveKcxNVNaUfnnG5ucwqEM1U24240XNRlWnvmaapg9f3qLhngU6r1w1I+qU8QJns0ld3xH3/BWcwLRW2rQwGaoM19b7XGfLp26F2+Z0rpR9fsJKOzI1oxR5bO0tjL5E3MeWGQ5CKtBmvomrlSCmFux6hYexcC3mZ2NnGyKMWnm1A7YiH7ypnApMeV0zDqM7OvpOnJk/WqBqONjaDWVGiqjy+Ts0wam15s0FYEbgk/ZJ+51LLpj62r0fsHjubUIhYcdnXpQkgxY6RzgmDDFjcPB4Zrx2S9Esphx+8dTWhEPuj5zrhCIoqJcNDpx2iWswC9tbxzZFoh09vcdU46/T8E5jZUCKqFNaE8o9R27q3lZ9ffykMp/e1WPerVPcOyb9lJkZGzve1mAN6aj7Pubx1+PmAg9jnzzywzF2aX7FStTqp7bhRZu7ShUAzYAsCHkG7IR7gU173s2Cp5f3/F2MR8hciXGq4//htwwAAAABJRU5ErkJggg==\" /></a>\n</div>\n  <div id=\"errorPageContainer\">\n  <table class='bodyTable'>\n    <tr>\n      <td class='bodyData'>\n<!--Contents-->\n<!-- FileName: cannotconnect.html\n     Language: [en]\n-->\n<!--Title-->\n<h1>Cannot Connect</h1>\n<!--/Title-->\n\n<!--Content-->\n<table class=\"contentTable\">\n  <tr>\n    <td class=\"contentData\">\n      The proxy could not connect to the destination in time.\n    </td>\n  </tr>\n</table>\n<!--/Content-->\n\n<!--Info-->\n<table class=\"infoTable\">\n  <tr>\n    <td class=\"infoData\">\n      <b>URL: </b><script type=\"text/javascript\">break_line(\"http://localhost:1500/v1/chat/completions\");</script><br />\n      <p class=\"proxyErrorData\">Failure Description: :cannotconnect:server state 1:state 9:Application response 502 cannotconnect</p>\n    </td>\n  </tr>\n</table>\n<!--/Info-->\n\n<!--/Contents-->\n      </td>\n    </tr>\n  </table>\n</div>\n<div id=\"debug\">\n  généré le 2023-10-31 09:46:28  par 10.129.42.32 - Client IP: 10.91.244.222 - Règle ID: 1015\n</div>\n</body>\n<!--/Body-->\n</html>\n)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 765\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(rbody)\n\u001b[0;32m    766\u001b[0m \u001b[39mexcept\u001b[39;00m (JSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\e43879\\Desktop\\Projets edf\\llama-index-docs\\test_llama_index.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/e43879/Desktop/Projets%20edf/llama-index-docs/test_llama_index.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#response = query_engine.query(\"what are the instructions to follow to go back to normal ?\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/e43879/Desktop/Projets%20edf/llama-index-docs/test_llama_index.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m response \u001b[39m=\u001b[39m query_engine\u001b[39m.\u001b[39;49mquery(\u001b[39m\"\u001b[39;49m\u001b[39mquelles sont les instructions pour revenir à la normale ?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/e43879/Desktop/Projets%20edf/llama-index-docs/test_llama_index.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#display(Markdown(f\"<b>{response}</b>\"))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\indices\\query\\base.py:32\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m     31\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(str_or_query_bundle)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\query_engine\\retriever_query_engine.py:182\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    176\u001b[0m         nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m    178\u001b[0m         retrieve_event\u001b[39m.\u001b[39mon_end(\n\u001b[0;32m    179\u001b[0m             payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mNODES: nodes},\n\u001b[0;32m    180\u001b[0m         )\n\u001b[1;32m--> 182\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_response_synthesizer\u001b[39m.\u001b[39;49msynthesize(\n\u001b[0;32m    183\u001b[0m         query\u001b[39m=\u001b[39;49mquery_bundle,\n\u001b[0;32m    184\u001b[0m         nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    187\u001b[0m     query_event\u001b[39m.\u001b[39mon_end(payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mRESPONSE: response})\n\u001b[0;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\response_synthesizers\\base.py:148\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[1;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     query \u001b[39m=\u001b[39m QueryBundle(query_str\u001b[39m=\u001b[39mquery)\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_manager\u001b[39m.\u001b[39mevent(\n\u001b[0;32m    146\u001b[0m     CBEventType\u001b[39m.\u001b[39mSYNTHESIZE, payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mQUERY_STR: query\u001b[39m.\u001b[39mquery_str}\n\u001b[0;32m    147\u001b[0m ) \u001b[39mas\u001b[39;00m event:\n\u001b[1;32m--> 148\u001b[0m     response_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_response(\n\u001b[0;32m    149\u001b[0m         query_str\u001b[39m=\u001b[39mquery\u001b[39m.\u001b[39mquery_str,\n\u001b[0;32m    150\u001b[0m         text_chunks\u001b[39m=\u001b[39m[\n\u001b[0;32m    151\u001b[0m             n\u001b[39m.\u001b[39mnode\u001b[39m.\u001b[39mget_content(metadata_mode\u001b[39m=\u001b[39mMetadataMode\u001b[39m.\u001b[39mLLM) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m nodes\n\u001b[0;32m    152\u001b[0m         ],\n\u001b[0;32m    153\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    156\u001b[0m     additional_source_nodes \u001b[39m=\u001b[39m additional_source_nodes \u001b[39mor\u001b[39;00m []\n\u001b[0;32m    157\u001b[0m     source_nodes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(nodes) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\response_synthesizers\\compact_and_refine.py:38\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m new_texts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_response(\n\u001b[0;32m     39\u001b[0m     query_str\u001b[39m=\u001b[39mquery_str,\n\u001b[0;32m     40\u001b[0m     text_chunks\u001b[39m=\u001b[39mnew_texts,\n\u001b[0;32m     41\u001b[0m     prev_response\u001b[39m=\u001b[39mprev_response,\n\u001b[0;32m     42\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kwargs,\n\u001b[0;32m     43\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\response_synthesizers\\refine.py:127\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m text_chunk \u001b[39min\u001b[39;00m text_chunks:\n\u001b[0;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m prev_response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m         \u001b[39m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         \u001b[39m# is an answer, then return it\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_give_response_single(\n\u001b[0;32m    128\u001b[0m             query_str, text_chunk, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kwargs\n\u001b[0;32m    129\u001b[0m         )\n\u001b[0;32m    130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m         \u001b[39m# refine response if possible\u001b[39;00m\n\u001b[0;32m    132\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_refine_response_single(\n\u001b[0;32m    133\u001b[0m             prev_response, query_str, text_chunk, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kwargs\n\u001b[0;32m    134\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\response_synthesizers\\refine.py:182\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[1;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streaming:\n\u001b[0;32m    179\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m         structured_response \u001b[39m=\u001b[39m cast(\n\u001b[0;32m    181\u001b[0m             StructuredRefineResponse,\n\u001b[1;32m--> 182\u001b[0m             program(\n\u001b[0;32m    183\u001b[0m                 context_str\u001b[39m=\u001b[39mcur_text_chunk,\n\u001b[0;32m    184\u001b[0m                 output_cls\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_cls,\n\u001b[0;32m    185\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    186\u001b[0m             ),\n\u001b[0;32m    187\u001b[0m         )\n\u001b[0;32m    188\u001b[0m         query_satisfied \u001b[39m=\u001b[39m structured_response\u001b[39m.\u001b[39mquery_satisfied\n\u001b[0;32m    189\u001b[0m         \u001b[39mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\response_synthesizers\\refine.py:53\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m StructuredRefineResponse:\n\u001b[1;32m---> 53\u001b[0m     answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_llm_predictor\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m     54\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prompt,\n\u001b[0;32m     55\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m     56\u001b[0m     )\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[39m=\u001b[39manswer, query_satisfied\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\llm_predictor\\base.py:191\u001b[0m, in \u001b[0;36mLLMPredictor.predict\u001b[1;34m(self, prompt, output_cls, **prompt_args)\u001b[0m\n\u001b[0;32m    189\u001b[0m     messages \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat_messages(llm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_llm, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprompt_args)\n\u001b[0;32m    190\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_messages(messages)\n\u001b[1;32m--> 191\u001b[0m     chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_llm\u001b[39m.\u001b[39;49mchat(messages)\n\u001b[0;32m    192\u001b[0m     output \u001b[39m=\u001b[39m chat_response\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\llms\\base.py:186\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[1;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mwith\u001b[39;00m wrapper_logic(_self) \u001b[39mas\u001b[39;00m callback_manager:\n\u001b[0;32m    178\u001b[0m     event_id \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_event_start(\n\u001b[0;32m    179\u001b[0m         CBEventType\u001b[39m.\u001b[39mLLM,\n\u001b[0;32m    180\u001b[0m         payload\u001b[39m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m         },\n\u001b[0;32m    185\u001b[0m     )\n\u001b[1;32m--> 186\u001b[0m     f_return_val \u001b[39m=\u001b[39m f(_self, messages, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f_return_val, Generator):\n\u001b[0;32m    189\u001b[0m         \u001b[39m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[0;32m    190\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_gen\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatResponseGen:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\llms\\openai.py:147\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     chat_fn \u001b[39m=\u001b[39m completion_to_chat_decorator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_complete)\n\u001b[1;32m--> 147\u001b[0m \u001b[39mreturn\u001b[39;00m chat_fn(messages, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\llms\\openai.py:208\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chat\u001b[39m(\u001b[39mself\u001b[39m, messages: Sequence[ChatMessage], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatResponse:\n\u001b[0;32m    207\u001b[0m     message_dicts \u001b[39m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[1;32m--> 208\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\n\u001b[0;32m    209\u001b[0m         is_chat_model\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    210\u001b[0m         max_retries\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries,\n\u001b[0;32m    211\u001b[0m         messages\u001b[39m=\u001b[39mmessage_dicts,\n\u001b[0;32m    212\u001b[0m         stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    213\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_all_kwargs(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    215\u001b[0m     message_dict \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     message \u001b[39m=\u001b[39m from_openai_message_dict(message_dict)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\llms\\openai_utils.py:139\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(is_chat_model, max_retries, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m     client \u001b[39m=\u001b[39m get_completion_endpoint(is_chat_model)\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\llama_index\\llms\\openai_utils.py:137\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    136\u001b[0m     client \u001b[39m=\u001b[39m get_completion_endpoint(is_chat_model)\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\site-packages\\openai\\api_requestor.py:767\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    765\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(rbody)\n\u001b[0;32m    766\u001b[0m \u001b[39mexcept\u001b[39;00m (JSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 767\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIError(\n\u001b[0;32m    768\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHTTP code \u001b[39m\u001b[39m{\u001b[39;00mrcode\u001b[39m}\u001b[39;00m\u001b[39m from API (\u001b[39m\u001b[39m{\u001b[39;00mrbody\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, rbody, rcode, headers\u001b[39m=\u001b[39mrheaders\n\u001b[0;32m    769\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    770\u001b[0m resp \u001b[39m=\u001b[39m OpenAIResponse(data, rheaders)\n\u001b[0;32m    771\u001b[0m \u001b[39m# In the future, we might add a \"status\" parameter to errors\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[39m# to better handle the \"error while streaming\" case.\u001b[39;00m\n",
      "\u001b[1;31mAPIError\u001b[0m: HTTP code 502 from API (<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html>\n<!-- FileName: index.html\n     Language: [en]\n-->\n<!--Head-->\n<head>\n  <meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\">\n  <title>Notification proxy</title>\n  <link rel=\"icon\" type=\"image/png\" href=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABmJLR0QA/wD/AP+gvaeTAAAA CXBIWXMAAC4jAAAuIwF4pT92AAAAB3RJTUUH4QscCiY57Z81SwAAAdhJREFUOMtt0ztsjXEY BvDfOU6Ixi2lEREVihAhymao6R8Jickl8i1iMRhZDIiFjYGFheW/NRHXhC9YtLFJ2qQlbk2k LnWpBi2ijqFvm6PxJf/le97nvT3PW1GUVdTlVDf9K8oOLMYNOf2YhlWh8h/SfCzFduzFbNzE VTyX00hjeEVRLsQWLMNctGIjqkF6i31Yjh704zM+oqeGnTiK7wG+x2V0y+lVdPUQm7EB67EE K9FZw4LIdhLdmCmnsX/GyukdbivKXnxFC46jpRYtjqJPTuMYi6oVzJDTb0U5B4cxLKdL+KIo X+NnFYNoxtppVeuYVGZH7OFTJG+LMd7UYuYPaEOXohTgiJxGFWUrDuJBLBVWhLzPqhjCC7Qr yoqc4ACOKMp52B9SnpfTn0iwGrPQX5XTVzzGJqyKgD5sxS3sDvJAtL8A7eiV01A1CF0Yx66Y /xouYCF65NTZsJ0OrMMNYRZyeonr2KMot8S/yeonGlzaHOM9ldP9iQRFWQv4CgZwWlGuiSR9 choMchPOYBHONVq5MiVbUa4OcDYu4h5+hdUPhc1PyenupFcqU5c1ueEJ2Y7FUp/gW3hkGGfl 9Cji/HuNExLWG1y4LV5TWPzO1ElPkCtyqv8FroChr3qq9H8AAAAASUVORK5CYII=\">\n  <script src=\"/mwg-internal/de5fs23hu73ds/files/javascript/sw.js\" type=\"text/javascript\" ></script>\n  <link rel=\"stylesheet\" href=\"/mwg-internal/de5fs23hu73ds/files/EDF-Template/stylesheet.css\" />\n</head>\n<!--/Head-->\n<!--Body-->\n<body onload=\"swOnLoad();\">\n<div id=\"warp\">\n    <a target=\"_blank\" href=\"http://localhost:1500/v1/chat/completions\" title=\"Page d'erreur complète\"><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAWCAYAAADTlvzyAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3wIZDyouwIzJ9QAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAB20lEQVRIx+2WPW/TYBCAn3PSgN2oKMZOascoQW0TiS0KAgmoZCYGBFtGEFOZGGBipH+AEdGJ3WslxEY3GCq2TEj8gFZsSBlAOYY2Td46Tp0qqhg46WTptc/PfduiqlykWFyw/FvA5zfF2QjEXxYJRCQUkfrRtVaTxmZFtveKcxNVNaUfnnG5ucwqEM1U24240XNRlWnvmaapg9f3qLhngU6r1w1I+qU8QJns0ld3xH3/BWcwLRW2rQwGaoM19b7XGfLp26F2+Z0rpR9fsJKOzI1oxR5bO0tjL5E3MeWGQ5CKtBmvomrlSCmFux6hYexcC3mZ2NnGyKMWnm1A7YiH7ypnApMeV0zDqM7OvpOnJk/WqBqONjaDWVGiqjy+Ts0wam15s0FYEbgk/ZJ+51LLpj62r0fsHjubUIhYcdnXpQkgxY6RzgmDDFjcPB4Zrx2S9Esphx+8dTWhEPuj5zrhCIoqJcNDpx2iWswC9tbxzZFoh09vcdU46/T8E5jZUCKqFNaE8o9R27q3lZ9ffykMp/e1WPerVPcOyb9lJkZGzve1mAN6aj7Pubx1+PmAg9jnzzywzF2aX7FStTqp7bhRZu7ShUAzYAsCHkG7IR7gU173s2Cp5f3/F2MR8hciXGq4//htwwAAAABJRU5ErkJggg==\" /></a>\n</div>\n  <div id=\"errorPageContainer\">\n  <table class='bodyTable'>\n    <tr>\n      <td class='bodyData'>\n<!--Contents-->\n<!-- FileName: cannotconnect.html\n     Language: [en]\n-->\n<!--Title-->\n<h1>Cannot Connect</h1>\n<!--/Title-->\n\n<!--Content-->\n<table class=\"contentTable\">\n  <tr>\n    <td class=\"contentData\">\n      The proxy could not connect to the destination in time.\n    </td>\n  </tr>\n</table>\n<!--/Content-->\n\n<!--Info-->\n<table class=\"infoTable\">\n  <tr>\n    <td class=\"infoData\">\n      <b>URL: </b><script type=\"text/javascript\">break_line(\"http://localhost:1500/v1/chat/completions\");</script><br />\n      <p class=\"proxyErrorData\">Failure Description: :cannotconnect:server state 1:state 9:Application response 502 cannotconnect</p>\n    </td>\n  </tr>\n</table>\n<!--/Info-->\n\n<!--/Contents-->\n      </td>\n    </tr>\n  </table>\n</div>\n<div id=\"debug\">\n  généré le 2023-10-31 09:46:28  par 10.129.42.32 - Client IP: 10.91.244.222 - Règle ID: 1015\n</div>\n</body>\n<!--/Body-->\n</html>\n)"
     ]
    }
   ],
   "source": [
    "#response = query_engine.query(\"what are the instructions to follow to go back to normal ?\")\n",
    "response = query_engine.query(\"quelles sont les instructions pour revenir à la normale ?\")\n",
    "#display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\e43879\\Desktop\\Projets edf\\llama-index-docs\\test_llama_index.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/e43879/Desktop/Projets%20edf/llama-index-docs/test_llama_index.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m node\u001b[39m.\u001b[39mnode\u001b[39m.\u001b[39mtext\n",
      "\u001b[1;31mNameError\u001b[0m: name 'node' is not defined"
     ]
    }
   ],
   "source": [
    "node.node.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Similarity Search\n",
      "File_name : FR01_FR10_2023_6239471443_YBF2_6239471443_ZB46_FR_0.PDF\n",
      "Page label : 2\n",
      "\n",
      "Document Similarity Search\n",
      "File_name : FR01_FR10_2023_6239471443_YBF2_6239471443_ZB46_FR_0.PDF\n",
      "Page label : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(\"Document Similarity Search\")\n",
    "    print(\"File name :\", response.metadata[node.node.id_][\"file_name\"])\n",
    "    print(\"Page label :\", response.metadata[node.node.id_][\"page_label\"])\n",
    "    #print(\"Meta Data :\", node.node.metadata)\n",
    "    #print(\"Text :\", node.node.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the provided context information, we cannot determine what specific situation is being referred to in the query \"quelles sont les instructions pour revenir à la normale ?\". Please provide more context or clarify your query for us to assist you further.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pour retourner à la normale selon l'information de contexte fournie, voici les étapes à suivre :\n",
      "\n",
      "1. Mode d'alimentation : Appuyez sur Fn + R pour activer le mode d'alimentation.\n",
      "2. Réinitialisation : Démarrez votre ordinateur en mode réinitialisation en appuyant sur le bouton \"Réinitialiser\" lors du démarrage.\n",
      "3. Désactiver la carte graphique Nvidia : Ouvrez msconfig en tapant \"msconfig\" dans le menu Démarrer ou recherchez \"msconfig\" dans le menu Rechercher Windows, puis sélectionnez l'onglet \"Boot\". Cochez l'option \"Advanced options pour Windows 10\" et cliquez sur le bouton \"Editer\". Dans la fenêtre suivante, décoquez\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"quelles sont les instructions pour revenir à la normale ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM's Response:\n",
      " give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example of 3 colors\n",
      "give example\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "os.environ['no_proxy'] = 'localhost,127.0.0.1' \n",
    "\n",
    "api_server_info = \"http://localhost:1300/v1\"\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key = \"anyValueYouLike\",\n",
    "    openai_api_base = api_server_info,\n",
    "    temperature = 0.2,\n",
    "    max_tokens = 100,\n",
    "    )\n",
    "\n",
    "prompt = \"give example of 3 colors\"\n",
    "response = llm(prompt=prompt)\n",
    "print(\"LLM's Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_API_BASE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\e43879\\Desktop\\Projets edf\\llama-index-docs\\test_llama_index.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/e43879/Desktop/Projets%20edf/llama-index-docs/test_llama_index.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/e43879/Desktop/Projets%20edf/llama-index-docs/test_llama_index.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mOPENAI_API_BASE\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\e43879\\AppData\\Local\\mambaforge\\envs\\llama_index\\lib\\os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    677\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[0;32m    678\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OPENAI_API_BASE'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_BASE']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
